<h1 align="center">ğŸš€ End-to-End AI-Powered Retention System</h1>

<p align="center">
  <a href="https://www.python.org/"><img src="https://img.shields.io/badge/Made%20with-Python-blue?logo=python"></a>
  <a href="https://pandas.pydata.org/"><img src="https://img.shields.io/badge/Data-Pandas%20%7C%20NumPy-150458?logo=pandas"></a>
  <a href="https://scikit-learn.org/"><img src="https://img.shields.io/badge/Framework-Scikit--learn-orange?logo=scikitlearn"></a>
  <a href="https://xgboost.readthedocs.io/"><img src="https://img.shields.io/badge/Models-XGBoost%20%7C%20LightGBM-2b6cb0"></a>
  <a href="https://shap.readthedocs.io/"><img src="https://img.shields.io/badge/Explainability-SHAP-6f42c1"></a>
  <img src="https://img.shields.io/badge/Status-Completed-success">
</p>

> ğŸ§  Predict customer churn at scale (1M rows) and enable retention strategies with a full, notebook-driven ML pipeline.

This project builds a production-style churn prediction workflowâ€”from raw data loading and cleaning to feature engineering, model training, and explainabilityâ€”using a large customer dataset.

## ğŸ¯ Objective
Build a machine learning model that predicts customer churn and identifies the most influential drivers to support targeted retention campaigns.

## ğŸ“¦ Dataset Overview
- **File:** customer_churn_1M.csv
- **Scaled:** ~1,000,000 rows, ~30 + columns
- **Target:** Churn (binary)
- **Source:** https://www.kaggle.com/datasets/isandeep06/customer-churn-prediction-dataset-1m

## ğŸ“Š Process Breakdown (Notebook.ipynb)

### Step 1. Data Loading & Profiling
- Load the dataset and verify shape, schema, and column types.
- Split columns into numerical and categorical groups.

### Step 2. Missing Value Treatment
- Compute missingness per column.
- Impute numerical with median and categorical with mode.

### Step 3. EDA (Exploratory Data Analysis)
- Distributions and outlier checks for numeric features.
- Category frequency and churn-rate analysis for categorical features.

### Step 4. Feature Engineering
- Clean column names and types.
- Binning, encoding, and optional missingness flags.

### Step 5. Modeling
- Train baseline and advanced models.
- Handle class imbalance (where needed) with imbalanced-learn.
- Evaluate with accuracy, F1, ROC-AUC, and confusion matrix.

### Step 6. Explainability
- Use SHAP to interpret global and local feature impact.

## ğŸ”§ Technologies & Libraries Used
- Python
- Pandas & NumPy
- Matplotlib & Seaborn
- Scikit-learn
- XGBoost & LightGBM
- imbalanced-learn
- SHAP

## ğŸ“ Project Structure

```
ğŸ“¦ End-to-End AI-Powered Retention System
â”œâ”€â”€ customer_churn_1M.csv
â”œâ”€â”€ End-to-End AI-Powered Retention System.txt
â”œâ”€â”€ Notebook.ipynb
â”œâ”€â”€ churn_model_artifact.pkl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš§ Ongoing Work
- Add production-grade feature store for reusable transformations.
- Build a lightweight inference API for churn scoring.
- Create automated data validation checks before training.
- Improve model monitoring and drift detection.

## ğŸ‘¨â€ğŸ’» Author
**Sandeep Maurya**

ğŸ“§ [isandeeep06@gmail.com](mailto:isandeeep06@gmail.com)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/sandeepmaurya-datascientist)  
ğŸŒ [Portfolio](https://isandeep06.github.io/)

---

## ğŸŒŸ Support
If this project helped you:

â­ Star this repo  
ğŸ“¢ Share it with others  
ğŸ’¬ Open an issue for suggestions or improvements
